## TextMEF: Text-guided Prompt Learning for Multi-exposure Image Fusion [IJCAI 2025]

[[paper]](https://www.ijcai.org/proceedings/2025/0175.pdf)

## :memo: TODO
- :white_check_mark: Release training and testing code.
- :white_check_mark: Release our training sets and test sets.
- :white_check_mark: Release pretrained checkpoints.

## :airplane: Environment

```shell
git clone https://github.com/hqj9994ever/SPRFusion.git
conda create -n SPRFusion python=3.8.18
conda activate SPRFusion
conda install cudatoolkit==11.8 -c nvidia
pip install torch==1.13.0 torchvision==0.14.0 torchaudio==0.13 --extra-index-url https://download.pytorch.org/whl/cu117
conda install -c "nvidia/label/cuda-11.8.0" cuda-nvcc
conda install packaging
pip install causal_conv1d==1.1.1 # or download causal_conv1d-1.1.1+cu118torch1.13cxx11abiFALSE-cp38-cp38-linux_x86_64.whl from https://github.com/Dao-AILab/causal-conv1d/releases/tag/v1.1.1 to install manually.
pip install mamba_ssm==1.1.1 # or download mamba_ssm-1.1.1+cu118torch1.13cxx11abiFALSE-cp38-cp38-linux_x86_64.whl from https://github.com/state-spaces/mamba/releases/tag/v1.1.1 to install manually.
pip install -r requirements.txt
```
Note: After installing the mamba library, replace the file content of `mamba_ssm/ops/selective_scan_interface.py` with that of `selective_scan_interface.py` from [Vim](https://github.com/hustvl/Vim).


#### ðŸ“‚ Data Preparation

You can download our training set and test set on [Google Drive](https://drive.google.com/drive/folders/1VsckjV152tF5As6gq7G1u7LOmzuIKhE3?usp=drive_link).

You should put the data in the correct place in the following form.

```
TextMEF ROOT
â””â”€â”€ Dataset
    â”œâ”€â”€ train_data
    â”‚   â””â”€â”€ SICE
    â”‚       â”œâ”€â”€ trainA
    â”‚       â”œâ”€â”€ trainB
    â”‚       â””â”€â”€ trainC
    â””â”€â”€ test_data
        â”œâ”€â”€ 31nogt
        â”‚   â”œâ”€â”€ over
        â”‚   â””â”€â”€ under
        â”œâ”€â”€ Mobile
        â”‚   â”œâ”€â”€ over
        â”‚   â”œâ”€â”€ under
        â”‚   â””â”€â”€ gt
        â””â”€â”€ SICE
            â”œâ”€â”€ over
            â”œâ”€â”€ under
            â””â”€â”€ gt
```


#### :cookie: Pretrained Checkpoints

Download the model weights on [Google Drive](https://drive.google.com/drive/folders/1VsckjV152tF5As6gq7G1u7LOmzuIKhE3?usp=drive_link) and put it in `model_zoo/`.

## :tennis: Train

### Prompt learning
```shell
python train_prompt.py \
--task_name train0 \
--lowlight_images_path 'path to ue image dir' \
--overlight_images_path 'path to oe image dir' \
--normallight_images_path 'path to gt image dir' \
--num_epochs 180 \
--prompt_lr 5e-5 \
--patch_size 224 \
--length_prompt 16 \
--load_pretrain False
```

### Train fusion network
```shell
python train.py \
--task_name train1 \
--lowlight_images_path 'path to ue image dir' \
--overlight_images_path 'path to oe image dir' \
--normallight_images_path 'path to gt image dir' \
--num_epochs 400 \
--train_lr 2e-4 \
--patch_size 224 \
--length_prompt 16 \
--load_pretrain True
```

## :gun: Evaluation

```shell
python test.py \
--input_u 'path to ue image dir' \
--input_o 'path to oe image dir' \
--gt 'path to GT dir (if GT exists)' \
--need_H (if GT exists) 
```

## :email: Contact
  If you have any other questions about the code, please open an issue in this repository or email us at  `hqj9994ever@gmail.com`.
